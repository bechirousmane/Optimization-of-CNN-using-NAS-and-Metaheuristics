\section*{Conclusion}
Ce travail a proposé une approche hybride innovante combinant la recherche d’architecture neuronale (NAS) et des algorithmes métaheuristiques inspirés des comportements naturels, tels que l’algorithme génétique et l’algorithme Firefly, pour l’optimisation des hyperparamètres structurels des réseaux de neurones convolutionnels. Les résultats expérimentaux obtenus sur les jeux de données MNIST et CIFAR-10 mettent en évidence la supériorité des méthodes métaheuristiques par rapport à la recherche aléatoire, tant en termes de précision que de capacité de généralisation. L’algorithme génétique s’est particulièrement distingué par sa capacité à explorer efficacement l’espace de recherche et à éviter les optima locaux, tandis que l’algorithme Firefly a montré une bonne aptitude à maintenir la diversité des solutions.
Au-delà des performances quantitatives, cette étude souligne l’importance de la représentation des architectures et de l’adaptation des opérateurs d’optimisation à la nature discrète et combinatoire du problème. L’intégration de NAS avec des métaheuristiques permet d’automatiser la conception de réseaux performants, tout en réduisant le coût computationnel associé à une exploration exhaustive.

\section*{Discussion des résultats}
Les résultats obtenus dans ce travail, bien qu’ils permettent de conclure sur la comparaison des algorithmes testés, restent loin d’être prometteurs du point de vue des performances absolues sur les jeux de données utilisés. Les scores atteints, notamment sur CIFAR-10, sont nettement inférieurs à ceux rapportés dans la littérature pour des architectures optimisées à l’état de l’art. De plus, les expériences menées sont très limitées en termes de taille de population, de nombre d’itérations et de ressources computationnelles, ce qui ne permet pas une évaluation exhaustive ni une comparaison directe avec les méthodes les plus performantes du domaine. Ces limitations doivent être prises en compte dans l’interprétation des résultats et invitent à considérer ce travail comme une preuve de concept plutôt qu’une solution compétitive.

\section*{Avantages de l’approche utilisée}
L’approche hybride proposée présente néanmoins plusieurs avantages notables. Elle permet d’automatiser le processus d’optimisation des architectures de réseaux de neurones, réduisant ainsi la dépendance à l’expertise humaine et le temps nécessaire à la conception manuelle. L’utilisation d’algorithmes métaheuristiques, tels que l’algorithme génétique et l’algorithme Firefly, offre une exploration efficace de vastes espaces de recherche, souvent inaccessibles aux méthodes classiques. Cette automatisation accélère le développement de modèles adaptés à des tâches spécifiques et facilite l’adaptation à de nouveaux jeux de données ou contraintes applicatives. De plus, la flexibilité de l’approche permet d’intégrer facilement d’autres critères d’optimisation, tels que la complexité du modèle ou la consommation de ressources.

\section*{Limitations}
Ce travail présente plusieurs limitations importantes. Tout d’abord, les ressources computationnelles disponibles ont fortement restreint la taille des populations, le nombre d’itérations et la diversité des expériences menées. Notre étude s’est également limitée à l’optimisation des hyperparamètres structurels des CNNs, sans explorer d’autres aspects tels que l’optimisation conjointe des paramètres d’entraînement ou la prise en compte de contraintes matérielles. La représentation de l’espace de recherche adoptée reste basique, alors qu’il existe des configurations plus robustes et expressives qui n’ont pas été explorées ici. Par ailleurs, l’algorithme Firefly\cite{FAfoundation} a été particulièrement pénalisé par la nature discrète de l’espace de recherche : les opérations euclidiennes classiques ne sont pas directement applicables, et il a fallu recourir à des mécanismes d’arrondi aléatoire pour adapter l’algorithme, ce qui a pu limiter son efficacité.

\section*{Travaux futurs}
Plusieurs axes d’amélioration peuvent être envisagés pour les travaux futurs. Il serait pertinent d’explorer d’autres algorithmes d’optimisation basés sur l’intelligence en essaim, tels que l’optimisation par essaim de particules (PSO\cite{kennedy1995particle}) ou les algorithmes de colonies de fourmis (ACO\cite{ACO}). L’étude de représentations plus riches et plus robustes de l’espace de recherche pourrait également permettre de découvrir des architectures plus performantes. L’intégration de techniques d’accélération de la recherche, comme le weight sharing\cite{pham2018efficient} ou l’évaluation partielle des architectures\cite{klein2017fast}, permettrait de tester un plus grand nombre de configurations en un temps réduit. Enfin, il serait essentiel de valider l’approche sur de véritables benchmarks de la communauté et de comparer systématiquement les résultats obtenus à l’état de l’art, afin d’évaluer le potentiel réel de la méthode proposée.

