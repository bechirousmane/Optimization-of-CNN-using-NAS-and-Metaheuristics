\section{Revue de la littérature}
La recherche par grille est une méthode classique et l'une des plus anciennes employée pour l'optimisation des hyperparamètres. Elle est efficace lorsque l'espace de recherche est relativement petit et devient très gourmande quand l'espace devient grand. Une autre méthode combinatoire qui est la recherche aléatoire\cite{JMLR:v13:bergstra12a}, est souvent utilisée. James et Bengio(2012)\cite{10.5555/2188385.2188395} ont montré empiriquement et théoriquement que la recherche aléatoire est plus efficace que la recherche par grille, notamment quand l'espace de recherche est relativement petit. L'optimisation bayésienne\cite{mockus1998application} est une méthode probabiliste sophistiqué basé sur le théorème de bayes. Les travaux de Wu et al\cite{WU201926}. ont montré que l'optimisation bayésienne basé sur le processus gaussien permet d'atteindre une grande précision(88,41\% après 50 itérations) sur le jeu de données CIFAR-10\cite{krizhevsky2009learning}. Les algorithmes méta-heuristiques tels que les algorithmes évolutionnaires ou les algorithmes basés sur l'intelligence en essaims sont plus robustes et mieux adaptés aux problèmes NP-difficiles\cite{np-dure}. Ces approches ont démontré leur efficacité dans l'optimisation des hyperparamètres des réseaux de neurones convolutionnels grâce à leur capacité à explorer efficacement des espaces de recherche complexes et non-convexes. Les algorithmes génétiques (GA)\cite{GenCNN} constituent l'une des approches les plus établies dans le domaine de l'optimisation évolutionnaire. Xie et Yuille (2017)\cite{GenCNN} ont proposé Genetic CNN, une approche qui utilise les principes évolutionnaires pour optimiser automatiquement les architectures de CNN. Leur méthode encode les architectures sous forme de chromosomes et applique des opérateurs de sélection, croisement et mutation pour explorer l'espace des architectures possibles. Cette approche a montré des résultats prometteurs sur les jeux de données CIFAR-10 et CIFAR-100. L'optimisation par essaim de particules (Particle Swarm Optimization, PSO) \cite{kennedy1995particle} s'inspire du comportement social des essaims d'oiseaux ou de poissons. Kennedy et Eberhart (1995)\cite{kennedy1995particle} ont introduit cette méthode qui a depuis été largement appliquée à l'optimisation des hyperparamètres des réseaux de neurones. PSO présente l'avantage de converger rapidement vers des solutions de qualité tout en maintenant une diversité dans la population de solutions. L'algorithme des lucioles (Firefly Algorithm, FA) \cite{FAfoundation} proposé par Yang (2009) s'inspire du comportement de clignotement des lucioles pour s'attirer mutuellement. Cet algorithme présente des caractéristiques intéressantes pour l'optimisation des CNN : il combine une exploration globale efficace avec une exploitation locale intensive. La nature décentralisée de FA permet une parallélisation naturelle, ce qui est particulièrement avantageux pour l'optimisation coûteuse des architectures de réseaux de neurones. 
Zoph et Le (2016)\cite{zoph2016neural} ont introduit le concept de NAS en utilisant l'apprentissage par renforcement pour explorer l'espace des architectures. Leur approche utilise un réseau de neurones récurrent comme contrôleur pour générer des descriptions d'architectures, qui sont ensuite évaluées sur un jeu de données cible. Liu et al\cite{Liu_2018_ECCV}. (2018) ont proposé Progressive NAS (PNAS), qui réduit significativement le coût computationnel en utilisant une stratégie de recherche progressive.
Tan et Le (2019)\cite{pmlr-v97-tan19a} ont développé EfficientNet, qui démontre l'importance du dimensionnement uniforme des réseaux (profondeur, largeur et résolution) et a établi de nouveaux standards de performance sur ImageNet. Ces travaux illustrent le potentiel de NAS pour découvrir des architectures qui surpassent les conceptions manuelles expertes. Les approches hybrides combinant NAS avec des algorithmes méta-heuristiques représentent une solution de recherche prometteuse. Ces méthodes tirent parti des avantages de chaque approche : la capacité de NAS à définir des espaces de recherche structurés et l'efficacité des méta-heuristiques à explorer des espaces complexes.
Des études récentes ont montré que l'utilisation d'algorithmes évolutionnaires dans le contexte de NAS peut améliorer significativement les performances tout en réduisant les coûts computationnels. EvoNAS-Rep\cite{WEN2022101191} a obtenu 96,35\% et 79,82\% de précision sur CIFAR-10 et CIFAR-100 avec seulement 0,2 GPU-jours, démontrant à la fois efficacité et performance. L'intégration de techniques d'intelligence en essaims avec NAS permet également une exploration plus diversifiée de l'espace des architectures, évitant ainsi les optima locaux qui peuvent limiter les approches traditionnelles. DeepSwarm\cite{deepSwarm} propose une méthode NAS basée sur l'optimisation par colonie de fourmis (ACO) qui combine la recherche progressive d'architecture neuronale avec la réutilisabilité des poids pour plus d'efficacité.
